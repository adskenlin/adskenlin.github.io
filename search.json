[{"title":"Deep Learning on LiDAR Data P1-Dataset","url":"/2021/08/16/Deep-Learning-on-NuScenes-LiDAR-Data/","content":"# P1 - NuScenes Dataset Introduction\n\n## Why NuScenes?\nWith increasing inverstment in fields of autonomous driving, tech-companies are creating their own dataset for training their autonomous vehicles. Some of them, like Waymo Dataset, Lyft L5 Dataset and NuScenes Data are widely used in personal uncommercial reasearchs because of their open-source and mutimodal features.\n\nNuScenes Dataset as one of the earliest published dataset in this field contains various kinds of data collected by different sensors such as cameras, radar and LiDARs. It provides toolkit to help researchers better get an overview and learn to process the data. And Lyft L5 Dataset also uses similiar toolkit as NuScenes.\n\nThe main reason, which persuade me starting with NuScenes is, the size of dataset. Since we are focusing on deep learning with LiDAR data, the most important factors of dataset is the number of LiDAR frames, annotated 3D boxes, different driving scenes. \n\n\n|Dataset|Scenes|Size|PCs lidar|Ann.Frames|3D boxes|\n|----|----|----|----|----|----|\n|NuScenes|1k|5.5hr|400k|40k|1.4M|\n|Lyft L5|366|2.5hr|46k|46k|1.3M|\n|Waymo Open|1k|5.5hr|200k|200k|12M|\n\nNuScenes has a larger data size comparing to Lyft L5, and has a easy-to-use toolkit comparing to Waymo Dataset. But for training a neural network, the more data we have, the better performance we could achieve. I mean starting with NuScenes should be the best way.\n\n## Toolkit(Devkit) Installation\nDevkit provides us various functions to extract the specific data format and data information from dataset. It also contains different matricies for evaluating NN(Neural Network)'s performance with respect to your goals such as prediction, detecton and so on.\n+ visit [official website](https://www.nuscenes.org/) and account registration\n+ Download Full dataset(v1.0): Trainval and Test Set\n+ Devkit Installation (for more information please visit their [github](https://github.com/nutonomy/nuscenes-devkit))\n> ```bash\n> # under Ubuntu or MacOS\n> # if you do not have python 3.6/3.7\n> # install python first\n> sudo apt install python-pip\n> sudo add-apt-repository ppa:deadsnakes/ppa\n> sudo apt-get update\n> sudo apt-get install python3.7\n> sudo apt-get install python3.7-dev\n> # then create virtual environment via conda or virtualenvwrapper\n> # if you do not have miniconda, google and install it\n> # after miniconda installed\n> conda create --name deep-learning-nuscenes python=3.7\n> conda activate deep-learning-nuscenes\n> # to deactivate env, use `source deactivate`\n> # then use\n> pip install nuscenes-devkit\n> ```\n+ Verify the installation and follow the tutorials [here](https://www.nuscenes.org/nuscenes?tutorial=nuscenes).\n\n## Data Format and Usage\nFrom tutorial you could see that there are many kinds of data formats in dataset such as `sample`, `sample_data`, `sample_annotation` and so on, but not all of them are useful for us. In this part, I would like to introduce the data, which is important for our focus.\n\nWhat kind of LiDAR data do we need for deep learning? An example of senor data processing from SOTA methods like Center-Net, MultiXNet shows the pipeline as follows: \n```txt\nRaw Point Cloud Data\n      |\n      | Aggretation\n      |\nAggregated Point Cloud Data\n      |\n      | with Annotation\n      |\nPoint Cloud Data with Annotation\n      |\n      | Construction\n      |\nInput Data for Model\n      |\n      | Voxelization\n      |\nVoxelized Point Cloud Data\n      |\n      | Dimension Transformation\n      |\nBird's Eye View(BEV)\n\n```\n\nMany experiments show that aggregation of several frames of LiDAR point clouds would enhance the perception performance of neural network, because one single frame of LiDAR point cloud doesn't contain enough information. From this point, we could decide, that we should extract successive frames of LiDAR point clouds and their annotation as well from dataset.\n\nFrom the tutorial, we could know sample means one frame, sample_data contains all sensor data of one frame, use devkit we could extract the LiDAR information specifically from sample_data. The LiDAR information here contains the path of LiDAR point cloud, annotations(annotated Objects) in this single frame.\n\nBasically, in one frame of LiDAR data we need to have:\n+ LiDAR Sweeps: Point clouds(Location X,Y,Z,Intensity,Ring Index)\n+ Annotations: Annotated Object Boxes(Location, dimension, Rotation, Velocity, Name of Object and so on)\n\nNow we know what kind of data we need, in next part I'd like to 'introduce data extraction pipeline for LiDAR data.\n\n\n\n## Reference\n[1] [nuScenes: A multimodal dataset for autonomous driving](https://arxiv.org/pdf/1903.11027.pdf)\n\n[2] [Center-based 3D Object Detection and Tracking](https://arxiv.org/pdf/2006.11275.pdf)\n","tags":["NuScenes","LiDAR","Deep Learning"]},{"title":"Solution to Problems You May Meet With Parallel System Ubuntu","url":"/2021/08/15/Solution-to-Problems-You-May-Meet-With-Parallel-System-Linux/","content":"This article collects the problems I met while I was installing Ubuntu and using Ubuntu at the beginning.\n## Normal Steps to Install Linux(Ubuntu)\n+ Download Ubuntu from [official website](https://ubuntu.com/download/desktop).\n+ Burn the .msi to your U-Disk with [Rufus](http://rufus.ie/en/).\n+ Prapare the Disk partition for Ubuntu System:\nWindows' Disk Management -> Right Click on your available Disk -> Shrink Volume... -> Set the space -> Shrink\n+ Turn off Win10 Quick Start\n+ Restart the PC, stick your U-Disk, go to BIOS Setting\n+ Choose \"UEFI: USB Flash Disk\" in start menu\n+ Choose \"Install Ubuntu\"\n+ Finish Installation and restart\n+ If your PC automatically use Windows, go to BIOS Setting again and choose ubuntu to start\n\n## Problems\n+ When you switch your system, the system time will be incorrect:\n\n```bash\n// Solution: Change UTC=yes to UTC=no in Linux \n// type in cmd:\ntimedatectl set-local-rtc 1 --adjust-system-clock\n```\n\n+ Installation freezes at the start and show checking nvidia driver:\n\n```txt\nSolution: \n1. when you see \"install Ubuntu\" etc.. (GRUB) press \"e\" quickly! \n2. Edit: Replace \"quiet splash\" to \"nomodeset\" and press F10 to boot.\n3. After installation done, and reboot.\n4. At the same place(GRUB), press \"e\" and in the line that starts with \"linux\", add \"nouveau.modeset=0\" at the end of that line. \n5. When you successfully enter Ubuntu, use Software and Update to install Nvidia Driver.\n```\n\n+ Connect Window's Disk in Ubuntu:\n```txt\nSolution:\n1. with `sudo fdisk -l` you could get an overview of all disk partitions.\n2. mark the name of device used by your windows disk, e.g. /dev/sda2.\n3. `sudo gedit /etc/fstab`\n4. add a line at the end with e.g.\n`/dev/sda2  /media/Data`\n5. the device would be able to visited through `/media/Data` in your ubuntu system\n```\n","tags":["Ubuntu"]},{"title":"CMake VS Code Setup on Windows","url":"/2021/08/13/CMake-VS-Code-Setup-on-Windows/","content":"# CMake VS Code Setup on Windows\nIn this article, I would like to introduce how to use CMake with VS Code on Windows.\n## What's CMake\n----\nCMake(Cross Platform Make) is free and open-source software for build automation, testing, packaging and installation of software by using a compiler-independent method. It's widely used in software projects. CMake offers higher-level mechanisms like external library detection and configuration (i.e. automatically setting up the defines, include directories and link files for working with a 3rd party library), support for generating installation (and packaging), integration with the CTest test utility and so on.\n\n\n## Installation\n----\nOn Windows, CMake could be directly downloaded und installed with their [official website](https://cmake.org/download/).\nAfter Installation, in order to use `cmake` in cmd, you have to add the path to your environments' variables following:\n\n\n    1. Click Start, type Accounts in the Start search box, and then click User Accounts under Programs.\n\n    2. If you are prompted for an administrator password or for a confirmation, type the password, or click Allow.\n\n    3. In the User Accounts dialog box, click Change my environment variables under Tasks.\n\n    4. Make the changes that you want to the user environment variables for your user account, and then click OK.\nTo verify installation, you could type `cmake --version` in your cmd/powershell.\n\nIn VS Code, make sure the `Extensions` named `CMake` and `CMake Tools` successfully installed.\n\n## Setup\n----\nAt the beginning, create a folder and use VS Code to open it. We'll use this folder to test the functions of CMake.  \n\nAdditionally, make sure you've correct configuration for compiler path in `C/C++: Edit Configurations(UI)`(use ctrl+shift+P and type in). In my case, the path is `C:/msys64/mingw64/bin/gcc.exe`.\n\nIt's highly recommanded that a C++ project with CMake use the folder architecture as follows:\n```bash\n|- test_folder\n    |--.vscode\n    |    |-- c_cpp_properties.json\n    |    |-- tasks.json\n    |    └-- launch.json\n    |-- build\n    |-- include\n    |    └-- your-head-files\n    |-- src\n    |    └-- source_code.cpp\n    └-- CMakeLists.txt\n```\nif you don't know how to get `c_cpp_properties.json`, `tasks.json`, `launch.json`, please refer to [here](https://code.visualstudio.com/docs/cpp/config-msvc) and [Debug using launch.json](https://code.visualstudio.com/docs/cpp/launch-json-reference) for help.\n\nThe core part is how to write the `CMakeLists.txt`:\nActually `cmake` is using `CMakeLists.txt` to execute build. A simple example:\n```cmake\ncmake_minimum_required (VERSION 2.8...3.21.1)\n\nproject(project_name)\n\ninclude_directories(${CMAKE_SOURCE_DIR}/include)\n\naux_source_directory(${CMAKE_SOURCE_DIR}/src DIR_SRC)\n\nadd_executable (project_name ${DIR_SRC})\n```\nThe variables and commands for `CMakeLists.txt` will be introduced in next part.\n\nNow we have all requirements for cmake, let's try:\n```bash\ncd build\ncmake ..\nmake\n```\nIf you don't have `make` installed, here is a short cut to make it work:\n1. Go to the folder where you install you compiler MinGW, in my case it's under `C:\\msys64\\mingw64\\bin`.\n2. Find a file named `mingw32-make.exe` and make a copy in the same foler.\n3. Rename the copy to `make.exe`.\n4. Check with `make --version` in cmd or powershell.\n\nIf the codes above work, you'll see *.exe created under `/build`, cmake works successfully.\n\n## Useful Variables and Commands for CMakeLists.txt\n----\nThe meaning of following words are able to be found under this [documentaion](https://cmake.org/cmake/help/latest/index.html)\n+ Variables: \n```cmake\nCMAKE_SOURCE_DIR\n\nPROJECT_SOURCE_DIR\n\nCMAKE_CURRENT_SOURCE_DIR\n\nCMAKE_MODULE_PATH\n\nEXECUTABLE_OUTPUT_PATH\n\nLIBRARY_OUTPUT_PATH\n\nPROJECT_NAME\n```\n+ Commands:\n```cmake\n// setup project name and supported progamming language\nproject(projectname [CXX] [C] [Java])\n\n// setup the supported cmake version \nCMAKE_MINIMUM_REQUIRED(VERSION versionNumber [FATAL_ERROR])\n\n// setup variables\nSET(VAR [VALUE] [CACHE TYPE DOCSTRING [FORCE]])\nset(EXECUTABLE_OUTPUT_PATH ${PROJECT_BINARY_DIR}/bin)\n\n// find all source code files and make them into a list\naux_source_directory(dir VARIABLE)\n\n// add subdirectory to the build\nadd_subdirectory(source_dir [binary_dir][EXCLUDE_FROM_ALL])\n\n// find head files\ninclude_directories([AFTER|BEFORE] [SYSTEM] dir1 dir2 ...)\n\n// Adds an executable target called <name> to be built from the source files listed\nadd_executable(<name> [source1] [source2 ...])\n\n// ...\n```\n## Reference:\n[1] [CMake Wiki](https://en.wikipedia.org/wiki/CMake) \\\n[2] [What are the benefits/purposes of cmake?](https://stackoverflow.com/questions/19686223/what-are-the-benefits-purposes-of-cmake) \\\n[3] [CMake Documentation](https://cmake.org/cmake/help/latest/index.html#)\n\n\n\n","tags":["CMake","VS Code"]},{"title":"How to Create Personal Blog on github Using Hexo","url":"/2021/07/28/personal_blogs/","content":"\n## Dependencies\n+ Node.js\n+ npm\n+ Git\n\n\n## Install Hexo\nif you don't have `node.js` and npm `npm` on your workstation, please visit [official site](https://nodejs.org/en/) to install the node.js. (npm would be automatically installed if node.js installation is done)\nTo check whether node.js and npm are successfully installed:\n```bash\n# in cmd/terminal\nnode -v # v14.17.3 or others\nnpm -v # 6.14.13 or others\n``` \nIf you are using win10 as your operate system and get errors with these codes, you should re-open the powershell/cmd as administor after the installation then try the codes above.\n\nThen:\n```bash\nnpm install -g hexo-cli\n```\nTo check whether hexo successfully installed:\n```bash\nhexo -v\n```\nYou'll see the version information e.g.:\n```bash\n hexo-cli:4.3.0, \n node:14.17.3, \n ... \n```\n\n## Create Blogs\nFirst of all, you have to navigate to the the folder, where you plan to create your blogs' folder.\n```bash\ncd E:\\\nmkdir my_blogs\ncd my_blogs\n```\nThen run:\n```bash\n# if you are using powershell as administor on windows,\nhexo init\n# if you are on mac/linux, \nsudo hexo init\n```\nCreate your first post:\n```bash\nhexo new \"My First Post\"\n```\nA new file with .md format will be created in `source/_posts/`. You could directly edit it in file. Also, you could preview your blog on your local machine with:\n```bash\n#establish a localhost for blog\nhexo server\n\n# if you have some updates to your blogs, use\nhexo clean\nhexo generate\nhexo server\n```\nThe response will show you a addresse like `http://localhost:4000`, you could visit it on local.\n\n\n## Deploy Blogs\nAfter you know how to write and make changes to your blogs on local, we'll introduce how to create a github page and deploy your blog to it. Install Deloyer with:\n```bash\nnpm install -save hexo-deployer-git\n``` \nGo to your github and create a new repositery called `username.github.io`. `username` should be your github username. This will be used as the address of github page later.\n\nOn your local, you need to edit the `_config.yml`. You could find this file in the blog folder. `_config.yml` is the key to set up your blogs, such as set up the name, discription, theme and so on. \n```bash\n# in _config.yml, find the part #Deployment change the info like below\ndeploy:\n  type: 'git'\n  repo: your-repo-adress\n  branch: master\n```\nAfter this, in your command line type:\n```bash\nhexo deploy\n```\nAfter a while, you would be able to visit `username.github.io` to see your own blog.\n\n## Change the Theme of Your Blog\nThere are varous free themes on [Hexo's official site](https://hexo.io/themes/). You could pick one to visit its github repo and follow the instruction to install it.\n\nE.g. I'd like to change the theme of my blog, firstly, \n```bash\n# in the path of your blog folder, clone the theme to local\ngit clone `url_of_the_theme_repo` themes/my_theme\n```\nThen modify the `_config.yml`. (most theme repos have demo, you could directly compare the `_config.yml` to your own and make some changes)\n\nAfter this:\n```bash\nhexo clean\nhexo generate\n# take a preview on local, \nhexo server\n# if everything is fine,\nhexo deploy\n```\n\n\n\nyou've successfully created your own blog! Congrats!"}]