<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="keyword"  content="">
    <link rel="shortcut icon" href="/img/favicon.ico">

    <title>
        
        Tech. Details of ONNX model and ONNX Runtime - Ken&#39;s TechBlog
        
    </title>

    <!-- Custom CSS -->
    
<link rel="stylesheet" href="/css/aircloud.css">

    
<link rel="stylesheet" href="/css/gitment.css">

    <!--<link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">-->
    <link href="//at.alicdn.com/t/font_620856_pl6z7sid89qkt9.css" rel="stylesheet" type="text/css">
    <!-- ga & ba script hoook -->
    <script></script>
<meta name="generator" content="Hexo 5.4.0"></head>

<body>

<div class="site-nav-toggle" id="site-nav-toggle">
    <button>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
    </button>
</div>

<div class="index-about">
    <i> write something </i>
</div>

<div class="index-container">
    
    <div class="index-left">
        
<div class="nav" id="nav">
    <div class="avatar-name">
        <div class="avatar ">
            <img src="/imgs/panda.jpeg" />
        </div>
        <div class="name">
            <i>Ken Lin</i>
        </div>
    </div>
    <div class="contents" id="nav-content">
        <ul>
            <li >
                <a href="/">
                    <i class="iconfont icon-shouye1"></i>
                    <span>HOME</span>
                </a>
            </li>
            <li >
                <a href="/tags">
                    <i class="iconfont icon-biaoqian1"></i>
                    <span>TAGS</span>
                </a>
            </li>
            <li >
                <a href="/archives">
                    <i class="iconfont icon-guidang2"></i>
                    <span>ARCHIVES</span>
                </a>
            </li>
            <li >
                <a href="/about/">
                    <i class="iconfont icon-guanyu2"></i>
                    <span>ABOUT</span>
                </a>
            </li>
            
            <li>
                <a id="search">
                    <i class="iconfont icon-sousuo1"></i>
                    <span>SEARCH</span>
                </a>
            </li>
            
        </ul>
    </div>
    
        <div id="toc" class="toc-article">
    <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Introduction"><span class="toc-text">Introduction</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Usage"><span class="toc-text">Usage</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Installation"><span class="toc-text">Installation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#To-obtain-an-ONNX-model"><span class="toc-text">To obtain an ONNX model</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Code-Example"><span class="toc-text">Code Example</span></a></li></ol></li></ol>
</div>
    
</div>


<div class="search-field" id="search-field">
    <div class="search-container">
        <div class="search-input">
            <span id="esc-search"> <i class="icon-fanhui iconfont"></i></span>
            <input id="search-input"/>
            <span id="begin-search">search</span>
        </div>
        <div class="search-result-container" id="search-result-container">

        </div>
    </div>
</div>

        <div class="index-about-mobile">
            <i> write something </i>
        </div>
    </div>
    
    <div class="index-middle">
        <!-- Main Content -->
        


<div class="post-container">
    <div class="post-title">
        Tech. Details of ONNX model and ONNX Runtime
    </div>

    <div class="post-meta">
        <span class="attr">Post：<span>2021-10-06 01:27:22</span></span>
        
        </span>
        <span class="attr">Visit：<span id="busuanzi_value_page_pv"></span>
</span>
</span>
    </div>
    <div class="post-content no-indent">
        <h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>ONNX(Open Neural Network Exchange) is a format of ML models which allows you to transform models between different frameworks. It provides a definition of an extensible computation graph model, as well as definitions of built-in operators and standard data types.</p>
<p>ONNX Runtime(ORT) is a performance-focused engine for ONNX models, which inferences efficiently across multiple platforms and hardware.</p>
<h2 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h2><h3 id="Installation"><a href="#Installation" class="headerlink" title="Installation"></a>Installation</h3><p>ONNX and ORT could be installed easily via:</p>
<blockquote>
<p><code>pip install onnx</code></p>
</blockquote>
<blockquote>
<p><code>pip install onnxruntime</code></p>
</blockquote>
<blockquote>
<p>or <code>pip install onnxruntime-gpu</code></p>
</blockquote>
<p>For conversion tools:</p>
<blockquote>
<p>PyTorch: <code>pip install torch</code></p>
</blockquote>
<blockquote>
<p>Tensorflow: <code>pip install tf2onnx</code></p>
</blockquote>
<blockquote>
<p>sklearn: <code>pip install skl2onnx</code></p>
</blockquote>
<p>ORT-Training:</p>
<blockquote>
<p><code>pip install torch-ort</code></p>
</blockquote>
<h3 id="To-obtain-an-ONNX-model"><a href="#To-obtain-an-ONNX-model" class="headerlink" title="To obtain an ONNX model"></a>To obtain an ONNX model</h3><ul>
<li><p><a target="_blank" rel="noopener" href="https://github.com/onnx/models">ONNX Model Zoo</a></p>
<p>In model zoo, it collects pre-trained models in various fields in ONNX format. For example, it provides Object Detection &amp; Image Segmentation models such as Yolov3, RetinaNet etc.</p>
</li>
<li><p>Export from other ML training frameworks</p>
<p>e.g. for PyTorch model, PyTorch provides built-in API to convert PyTorch model to ONNX model. </p>
</li>
<li><p>Convert using ONNX provided tools</p>
<p>e.g. For TensorFlow model, <a target="_blank" rel="noopener" href="https://github.com/onnx/tensorflow-onnx">ONNX’ repo</a> provides tools for conversion of TF/Keras/tensorflow.js/TFLite models.</p>
</li>
</ul>
<h3 id="Code-Example"><a href="#Code-Example" class="headerlink" title="Code Example"></a>Code Example</h3><ol>
<li><p>PyTorch-Conversion</p>
<ul>
<li><p>Export Model</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">torch.onnx.export(model,</span><br><span class="line">                  torch.randn(<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>).to(device),</span><br><span class="line">                  <span class="string">&quot;mnist_model.onnx&quot;</span>,</span><br><span class="line">                  input_names = [<span class="string">&#x27;input&#x27;</span>],</span><br><span class="line">                  output_names = [<span class="string">&#x27;output&#x27;</span>])</span><br></pre></td></tr></table></figure></li>
<li><p>Load Model</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> onnx</span><br><span class="line">onnx_model = onnx.load(<span class="string">&quot;mnist_model.onnx&quot;</span>)</span><br><span class="line">onnx.checker.check_model(onnx_model)</span><br></pre></td></tr></table></figure></li>
<li><p>Create inference session using <code>ort.InferenceSession</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> onnxruntime <span class="keyword">as</span> ort</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">x, y = test_data[<span class="number">0</span>][<span class="number">0</span>], test_data[<span class="number">0</span>][<span class="number">1</span>]</span><br><span class="line">ort_sess = ort.InferenceSession(<span class="string">&#x27;mnist_model.onnx&#x27;</span>)</span><br><span class="line">outputs = ort_sess.run(<span class="literal">None</span>, &#123;<span class="string">&#x27;input&#x27;</span>: x.numpy()&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print Result </span></span><br><span class="line">predicted, actual = classes[outputs[<span class="number">0</span>][<span class="number">0</span>].argmax(<span class="number">0</span>)], classes[y]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Predicted: &quot;<span class="subst">&#123;predicted&#125;</span>&quot;, Actual: &quot;<span class="subst">&#123;actual&#125;</span>&quot;&#x27;</span>)</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>TensorFlow-Conversion</p>
<ul>
<li><p>Save Model</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.applications.resnet50 <span class="keyword">import</span> ResNet50</span><br><span class="line"><span class="keyword">import</span> onnxruntime</span><br><span class="line"></span><br><span class="line">model = ResNet50(weights=<span class="string">&#x27;imagenet&#x27;</span>)</span><br><span class="line"></span><br><span class="line">preds = model.predict(x)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Keras Predicted:&#x27;</span>, decode_predictions(preds, top=<span class="number">3</span>)[<span class="number">0</span>])</span><br><span class="line">model.save(os.path.join(<span class="string">&quot;/tmp&quot;</span>, model.name))</span><br></pre></td></tr></table></figure></li>
<li><p>Conversion and Export</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tf2onnx</span><br><span class="line"><span class="keyword">import</span> onnxruntime <span class="keyword">as</span> rt</span><br><span class="line"></span><br><span class="line">spec = (tf.TensorSpec((<span class="literal">None</span>, <span class="number">224</span>, <span class="number">224</span>, <span class="number">3</span>), tf.float32, name=<span class="string">&quot;input&quot;</span>),)</span><br><span class="line">output_path = model.name + <span class="string">&quot;.onnx&quot;</span></span><br><span class="line"></span><br><span class="line">model_proto, _ = tf2onnx.convert.from_keras(model, input_signature=spec, opset=<span class="number">13</span>, output_path=output_path)</span><br><span class="line">output_names = [n.name <span class="keyword">for</span> n <span class="keyword">in</span> model_proto.graph.output]</span><br></pre></td></tr></table></figure></li>
<li><p>Create inference session with <code>rt.infernnce</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">providers = [<span class="string">&#x27;CPUExecutionProvider&#x27;</span>]</span><br><span class="line">m = rt.InferenceSession(output_path, providers=providers)</span><br><span class="line">onnx_pred = m.run(output_names, &#123;<span class="string">&quot;input&quot;</span>: x&#125;)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;ONNX Predicted:&#x27;</span>, decode_predictions(onnx_pred[<span class="number">0</span>], top=<span class="number">3</span>)[<span class="number">0</span>])</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>ORT-Training Example</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch_ort</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TestNet</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, input_size, hidden_size, num_classes</span>):</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">model = TestNet(input_size=<span class="number">512</span>, hidden_size=<span class="number">256</span>, num_classes=<span class="number">10</span>)</span><br><span class="line"><span class="comment"># use ORT-Training</span></span><br><span class="line">model = torch_ort.ORTModule(model)</span><br><span class="line"></span><br><span class="line">criterion = torch.nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=<span class="number">1e-4</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> data, target <span class="keyword">in</span> data_loader:</span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    y_pred = model(data)</span><br><span class="line">    loss = criterion(output, target)</span><br><span class="line"></span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br></pre></td></tr></table></figure>
<p>As some blogs like <a target="_blank" rel="noopener" href="https://cloudblogs.microsoft.com/opensource/2021/07/13/accelerate-pytorch-training-with-torch-ort/">Accelerate PyTorch training with torch-ort</a>, <a target="_blank" rel="noopener" href="https://techcommunity.microsoft.com/t5/azure-ai/accelerate-pytorch-transformer-model-training-with-onnx-runtime/ba-p/2540471">Accelerate PyTorch transformer model training with ONNX Runtime – a deep dive</a> shown, ONNX Runtime could accelerate some deep learning models’ fune-tuning by 20%-40% performance in compare with pure PyTorch.</p>
</li>
</ol>

        
        <br />
        <div id="comment-container">
        </div>
        <div id="disqus_thread"></div>

        <div id="lv-container">
        </div>

    </div>
</div>

    </div>
</div>


<footer class="footer">
    <ul class="list-inline text-center">
        
        

        

        

        
        <li>
            <a target="_blank"  href="https://github.com/adskenlin">
                            <span class="fa-stack fa-lg">
                                <i class="iconfont icon-github"></i>
                            </span>
            </a>
        </li>
        

        
        <li>
            <a target="_blank"  href="https://www.linkedin.com/in/kenlin93">
                            <span class="fa-stack fa-lg">
                                <i class="iconfont icon-linkedin"></i>
                            </span>
            </a>
        </li>
        

    </ul>
    
    <p>
        <span id="busuanzi_container_site_pv">
            <span id="busuanzi_value_site_pv"></span>PV
        </span>
        <span id="busuanzi_container_site_uv">
            <span id="busuanzi_value_site_uv"></span>UV
        </span>
        Created By <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>  Theme <a target="_blank" rel="noopener" href="https://github.com/aircloud/hexo-theme-aircloud">AirCloud</a></p>
</footer>




</body>

<script>
    // We expose some of the variables needed by the front end
    window.hexo_search_path = "search.json"
    window.hexo_root = "/"
    window.isPost = true
</script>
<script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script>

<script src="/js/index.js"></script>

<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




</html>
